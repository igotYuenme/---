import requests
import pandas as pd
import time

# -----------------------------
# é…ç½®
# -----------------------------
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.7499.41 Safari/537.36",
    "cookie": "gid=yjDJySdS0Y0dyjDJySd0fhDVdD2TWx12YVADJU0h6YSUdD286iE6fd888yj22q48j0fKi24d;loadts=1765798751723;sec_poison_id=9aeb7f24-dc32-4135-97bd-f3e9a8369cbe;unread=9aeb7f24-dc32-4135-97bd-f3e9a8369cbe;web_session=04006979c29a22dc9a3312bb0a3b4bf4105ef0;webBuild=5.0.6;webld=f36c57760a55a5aae93dbafa56a308c8;websectiga=634d3ad75ffb42a2ade2c5e1705a73c845837578aeb31ba0e442d75c648da36a; xsecappid=xhs-pc-web",
    "Referer": "https://www.xiaohongshu.com/"
}

SEARCH_URL = "https://edith.xiaohongshu.com/api/sns/web/v1/search/notes"

KEYWORDS = [
    'æ˜Ÿè±¡åˆ†æ',      # æ›¿ä»£ æ˜Ÿåº§
    'æŠ½ç‰Œå»ºè®®',      # æ›¿ä»£ å¡”ç½—
    'æ°´é€†',
    'è¿åŠ¿',
    'æ˜Ÿç›˜è¿åŠ¿',      # æ›¿ä»£ æ˜Ÿç›˜
    'MBTI',
    'æ˜¾åŒ–',
    'å¸å¼•åŠ›æ³•åˆ™',
    'è€ƒå‰ å»ºè®®',     # æ›¿ä»£ è€ƒå‰ å åœ
    'åˆ†æ‰‹ å»ºè®®',     # æ›¿ä»£ åˆ†æ‰‹ å¡”ç½—
    'é¢è¯• å»ºè®®',     # æ›¿ä»£ é¢è¯• æ˜Ÿåº§
    'è€ƒè¯• è¿åŠ¿'
]

MAX_PAGES = 3  # æ¯ä¸ªå…³é”®è¯æŠ“å–é¡µæ•°ï¼Œæ¯é¡µå¤§çº¦ 10 æ¡ç¬”è®°
SLEEP_TIME = 1  # è¯·æ±‚é—´éš”ï¼Œé¿å…å° IP

# -----------------------------
# å°çº¢ä¹¦ç¬”è®°æŠ“å–å‡½æ•°
# -----------------------------
def fetch_notes(keyword, pages=MAX_PAGES):
    notes = []
    for page in range(1, pages + 1):
        # å…³é”®ï¼šæ„å»ºä¸€ä¸ªåŒ…å«æ›´å¤šå‚æ•°çš„è¯·æ±‚
        params = {
            "keyword": keyword,
            "page": page,
            "page_size": 20,  # æ¯é¡µæ•°é‡å¯å°è¯•è°ƒæ•´
            "sort": "general",  # æ’åºæ–¹å¼ï¼šgeneral(ç»¼åˆ) time_desc(æœ€æ–°)
            # æ ¹æ®é€†å‘åˆ†æï¼Œå¯èƒ½è¿˜éœ€è¦ä»¥ä¸‹å‚æ•°ï¼š
            # "search_id": "ç”Ÿæˆä¸€ä¸ªéšæœºID",
            # "source": "input",
            # "need_web_search": "true",
        }
        try:
            resp = requests.get(SEARCH_URL, headers=HEADERS, params=params, timeout=15)
            print(f"è°ƒè¯•ä¿¡æ¯: çŠ¶æ€ç  {resp.status_code}, å“åº”é•¿åº¦ {len(resp.text)}")
            print(f"å“åº”å‰100å­—ç¬¦: {resp.text[:100]}") # æŸ¥çœ‹å“åº”å†…å®¹ï¼Œå¸®åŠ©åˆ¤æ–­
            
            # å°è¯•è§£æJSON
            data = resp.json()
            # æ³¨æ„ï¼šæ•°æ®å±‚çº§ç»“æ„å¾ˆå¯èƒ½å·²ç»æ”¹å˜ï¼Œéœ€è¦ä½ æ ¹æ®å®é™…è¿”å›çš„JSONç»“æ„è°ƒæ•´
            items = data.get("data", {}).get("items", [])  # è¿™é‡Œåªæ˜¯å‡è®¾ï¼Œéœ€è°ƒæ•´
            if not items:
                # ä¹Ÿå¯èƒ½åœ¨åˆ«çš„å­—æ®µé‡Œ
                items = data.get("data", {}).get("notes", [])
                items = data.get("data", {}).get("list", [])
            
            for item in items:
                note = {
                    "keyword": keyword,
                    "title": item.get("title") or item.get("note_card", {}).get("display_title", ""),
                    "desc": item.get("desc") or item.get("note_card", {}).get("desc", ""), # å¢åŠ å†…å®¹å­—æ®µ
                    "author": item.get("user", {}).get("nickname", ""),
                    "likes": item.get("likes") or item.get("note_card", {}).get("interact_info", {}).get("liked_count", 0),
                    "comments": item.get("comments") or item.get("note_card", {}).get("interact_info", {}).get("comment_count", 0),
                    "favorites": item.get("favorites") or item.get("note_card", {}).get("interact_info", {}).get("collected_count", 0),
                    "note_id": item.get("id", ""),
                    "link": f"https://www.xiaohongshu.com/explore/{item.get('id', '')}"
                }
                notes.append(note)
            print(f"[INFO] {keyword} page={page} è·å– {len(items)} æ¡ç¬”è®°")
            time.sleep(SLEEP_TIME)
        except requests.exceptions.RequestException as e:
            print(f"[ERROR] ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
        except ValueError as e:
            print(f"[ERROR] è§£æJSONå¤±è´¥ï¼Œå“åº”å¯èƒ½ä¸æ˜¯JSONæ ¼å¼ã€‚åŸå§‹å“åº”å¼€å¤´: {resp.text[:200]}")
            # è¿™é‡Œå¾ˆå¯èƒ½æ˜¯é‡åˆ°äº†åçˆ¬ï¼Œè¿”å›äº†éªŒè¯é¡µé¢
        except Exception as e:
            print(f"[ERROR] å…¶ä»–é”™è¯¯: {e}")
    return notes


# -----------------------------
# ä¸»ç¨‹åº
# -----------------------------
if __name__ == "__main__":
    all_notes = []
    for kw in KEYWORDS:
        print(f"ğŸ” æœç´¢å…³é”®è¯: {kw}")
        notes = fetch_notes(kw, pages=MAX_PAGES)
        all_notes.extend(notes)

    if all_notes:
        df = pd.DataFrame(all_notes)
        df.to_csv("xiaohongshu_notes.csv", index=False, encoding="utf-8-sig")
        print(f"ğŸ’¾ å·²ä¿å­˜ {len(df)} æ¡ç¬”è®°è‡³ xiaohongshu_notes.csv")
    else:
        print("âš ï¸ æœªæŠ“å–åˆ°ä»»ä½•ç¬”è®°ï¼Œè¯·æ£€æŸ¥ Cookie æˆ–å…³é”®è¯")
