# ======================================
# æ”¶é›†UPä¸»æœ¬äººçš„è§†é¢‘å†…å®¹
# åŠŸèƒ½ï¼šä¸“é—¨æ”¶é›†æŒ‡å®šUPä¸»ï¼ˆå¦‚"é¾™å¥³å¡”ç½—"ï¼‰å‘å¸ƒçš„è§†é¢‘
# ======================================

import requests
import time
import random
import pandas as pd
from datetime import datetime

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
    "Referer": "https://www.bilibili.com/",
    "Accept": "application/json, text/plain, */*",
    "Accept-Language": "zh-CN,zh;q=0.9",
}

# âš ï¸ ç”¨ä½ æµè§ˆå™¨é‡Œçš„ cookie
COOKIES = {
    "SESSDATA": "fe6b47f8%2C1781276922%2C9218b%2Ac1CjCj2ylimx2cRdVzjuVh3-dT6p_21q9h88Jk2qpoSwgIMS_h10xgu3tKqlkMuDwpVqISVlJqN2FhTWpPUWJZdE5ELVh0Q1o1a2ZSSndTTV8yQXdYNlY3UEZaNmtvck1VVXpVeHlVd05iSUowN2xzUlBnV1J6ZHZDVDNOVlNkRjZobzRYRUZySV93IIEC",
    "bili_jct": "4cc35775f5ade0d0803a91688acc8869",
}

def search_up_videos(up_name, max_pages=20):
    """
    æœç´¢UPä¸»çš„è§†é¢‘ï¼ˆé€šè¿‡æœç´¢UPä¸»åç§°ï¼Œç„¶åè¿‡æ»¤ä½œè€…å­—æ®µï¼‰
    
    Args:
        up_name: UPä¸»åç§°ï¼Œå¦‚"é¾™å¥³å¡”ç½—"
        max_pages: æœ€å¤§æœç´¢é¡µæ•°
    
    Returns:
        list: è§†é¢‘æ•°æ®åˆ—è¡¨
    """
    print(f"ğŸ” å¼€å§‹æ”¶é›†UPä¸» '{up_name}' çš„è§†é¢‘...")
    all_results = []
    seen_bvids = set()  # ç”¨äºå»é‡
    
    # æœç´¢UPä¸»åç§°
    for page in range(1, max_pages + 1):
        url = "https://api.bilibili.com/x/web-interface/search/type"
        params = {
            "search_type": "video",
            "keyword": up_name,  # æœç´¢UPä¸»åç§°
            "page": page
        }
        
        try:
            r = requests.get(
                url,
                headers=HEADERS,
                cookies=COOKIES,
                params=params,
                timeout=10
            )
            
            if r.status_code != 200 or not r.text.strip():
                print(f"  [WARN] ç¬¬{page}é¡µè¿”å›ç©ºå†…å®¹ï¼Œåœæ­¢æœç´¢")
                break
            
            data = r.json()
            
            # æ£€æŸ¥APIè¿”å›çŠ¶æ€
            if data.get('code') != 0:
                print(f"  [WARN] APIè¿”å›é”™è¯¯: {data.get('message', 'æœªçŸ¥é”™è¯¯')}")
                break
            
            items = data.get("data", {}).get("result", [])
            if not items:
                print(f"  [INFO] ç¬¬{page}é¡µæ— ç»“æœï¼Œåœæ­¢æœç´¢")
                break
            
            page_count = 0
            for v in items:
                author = v.get("author", "")
                bvid = v.get("bvid", "")
                
                # åªæ”¶é›†UPä¸»æœ¬äººçš„è§†é¢‘ï¼ˆç²¾ç¡®åŒ¹é…ä½œè€…åï¼‰
                if author == up_name and bvid and bvid not in seen_bvids:
                    seen_bvids.add(bvid)
                    all_results.append({
                        "keyword": f"UPä¸»:{up_name}",  # æ ‡è®°ä¸ºUPä¸»è§†é¢‘
                        "title": v.get("title", "").replace("<em class=\"keyword\">", "").replace("</em>", ""),
                        "up": author,
                        "play": v.get("play", 0),
                        "danmu": v.get("danmaku", 0),
                        "pubdate": v.get("pubdate", 0),
                        "bvid": bvid,
                        "link": f"https://www.bilibili.com/video/{bvid}"
                    })
                    page_count += 1
            
            print(f"  ç¬¬{page}é¡µ: æ‰¾åˆ°{page_count}ä¸ªUPä¸»è§†é¢‘ (ç´¯è®¡: {len(all_results)})")
            
            # å¦‚æœè¿™ä¸€é¡µæ²¡æœ‰æ‰¾åˆ°UPä¸»è§†é¢‘ï¼Œå¯èƒ½å·²ç»åˆ°åº•äº†
            if page_count == 0:
                print(f"  è¿ç»­å¤šé¡µæ— UPä¸»è§†é¢‘ï¼Œåœæ­¢æœç´¢")
                break
            
            time.sleep(random.uniform(2, 4))  # é¿å…è¯·æ±‚è¿‡å¿«
            
        except Exception as e:
            print(f"  [ERROR] ç¬¬{page}é¡µå¼‚å¸¸: {e}")
            continue
    
    print(f"âœ… å…±æ”¶é›†åˆ° {len(all_results)} ä¸ªUPä¸» '{up_name}' çš„è§†é¢‘")
    return all_results

def collect_up_videos(up_name="é¾™å¥³å¡”ç½—", max_pages=30, save_file=None):
    """
    æ”¶é›†UPä¸»çš„è§†é¢‘å¹¶ä¿å­˜åˆ°CSVæ–‡ä»¶
    
    Args:
        up_name: UPä¸»åç§°
        max_pages: æœ€å¤§æœç´¢é¡µæ•°
        save_file: ä¿å­˜æ–‡ä»¶åï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
    """
    print("=" * 70)
    print(f"æ”¶é›†UPä¸»è§†é¢‘å†…å®¹: {up_name}")
    print("=" * 70)
    print()
    
    # æ”¶é›†è§†é¢‘
    videos = search_up_videos(up_name, max_pages=max_pages)
    
    if len(videos) == 0:
        print("âŒ æœªæ”¶é›†åˆ°ä»»ä½•è§†é¢‘ï¼Œè¯·æ£€æŸ¥:")
        print("   1. UPä¸»åç§°æ˜¯å¦æ­£ç¡®")
        print("   2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("   3. Cookieæ˜¯å¦æœ‰æ•ˆ")
        return None
    
    # è½¬æ¢ä¸ºDataFrame
    df = pd.DataFrame(videos)
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š æ”¶é›†ç»“æœç»Ÿè®¡:")
    print(f"   è§†é¢‘æ€»æ•°: {len(df)}")
    if 'play' in df.columns:
        total_views = pd.to_numeric(df['play'], errors='coerce').sum()
        avg_views = pd.to_numeric(df['play'], errors='coerce').mean()
        print(f"   æ€»æ’­æ”¾é‡: {total_views:,.0f}")
        print(f"   å¹³å‡æ’­æ”¾é‡: {avg_views:,.0f}")
    
    if 'danmu' in df.columns:
        total_danmu = pd.to_numeric(df['danmu'], errors='coerce').sum()
        print(f"   æ€»å¼¹å¹•æ•°: {total_danmu:,.0f}")
    
    # ä¿å­˜æ–‡ä»¶
    if save_file is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        save_file = f"{up_name}_videos_{timestamp}.csv"
    
    df.to_csv(save_file, index=False, encoding="utf-8-sig")
    print(f"\nğŸ’¾ å·²ä¿å­˜åˆ°: {save_file}")
    
    return df

if __name__ == "__main__":
    # é…ç½®å‚æ•°
    UP_NAME = "é¾™å¥³å¡”ç½—"
    MAX_PAGES = 30  # å¢åŠ é¡µæ•°ä»¥è·å–æ›´å¤šè§†é¢‘
    
    df = collect_up_videos(UP_NAME, max_pages=MAX_PAGES)
    
    if df is not None:
        print(f"\nâœ… æ”¶é›†å®Œæˆï¼")
        print(f"   æ–‡ä»¶å·²ä¿å­˜ï¼Œå¯åœ¨longnv.pyä¸­ä½¿ç”¨")

