import requests
import json
import time
import random
from datetime import datetime
import urllib3
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

urllib3.disable_warnings()

COOKIE = 'WEIBOCN_FROM=1110006030; _T_WM=99895283787; SCF=At_bl9yByv0ENbFBSKWHytS7iH19oSoSfd_9dSXjyskqMABoeCjyLnQJ1gvzU8bXVoijHRwx32Q3KCGyQGa4Du8.; SUB=_2A25EOFU3DeRhGeBM6lUQ-C_Nzz-IHXVnNOj_rDV6PUJbktANLU7ckW1NRDAG61lJHxT9WgTcouUX7_VvbeuFW2Id; SUBP=0033WrSXqPxfM725Ws9jqgMF55529P9D9WWB.cA_nFF2RAP6OksIX5YY5NHD95Qceo2NeKnpeKB0Ws4Dqcj6i--ciKy2iKysi--fiKysi-8Wi--fi-z7iKysi--4i-zpi-ihi--fiKLhiKnci--fiKLhiKnci--fiKLhiKnc; SSOLoginState=1765549415; ALF=1768141415; MLOGIN=1; XSRF-TOKEN=f5f68c; M_WEIBOCN_PARAMS=lfid%3D102803%26luicode%3D20000174%26uicode%3D20000174'

headers = {
    'User-Agent': 'Mozilla/5.0 (Linux; Android 10; Pixel 5) AppleWebKit/537.36 '
                  '(KHTML, like Gecko) Chrome/120.0 Mobile Safari/537.36',
    'Cookie': COOKIE,
    'Referer': 'https://m.weibo.cn/'
}

KEYWORDS = [
    # æ ¸å¿ƒå…³é”®è¯ï¼ˆé«˜é¢‘ï¼‰
    'æ˜Ÿè±¡åˆ†æ',
    'æŠ½ç‰Œå»ºè®®',
    'æ°´é€†',
    'è¿åŠ¿',
    'æ˜Ÿç›˜è¿åŠ¿',
    'MBTI',
    'æ˜¾åŒ–',
    'å¸å¼•åŠ›æ³•åˆ™',
    # å­¦ä¸š/èŒä¸šç›¸å…³ï¼ˆå¿ƒç†æ…°è—‰å‹ï¼‰
    'è€ƒå‰ å»ºè®®',
    'è€ƒè¯• è¿åŠ¿',
    'é¢è¯• å»ºè®®',
    'æ±‚èŒ è¿åŠ¿',
    'è€ƒç ” è¿åŠ¿',
    'æ¯•ä¸š å»ºè®®',
    'å®ä¹  å»ºè®®',
    'offer è¿åŠ¿',
    'è®ºæ–‡ å»ºè®®',
    # æƒ…æ„Ÿç›¸å…³ï¼ˆå¨±ä¹å‹ï¼‰
    'åˆ†æ‰‹ å»ºè®®',
    'å¤åˆ è¿åŠ¿',
    'æ‹çˆ± å»ºè®®',
    'æ¡ƒèŠ± è¿åŠ¿',
    'å‰ä»» å»ºè®®',
    'æš§æ˜§ å»ºè®®',
    # æ‰©å±•å…³é”®è¯
    'å¡”ç½—ç‰Œ',
    'å åœ',
    'æ˜Ÿåº§è¿åŠ¿',
    'å¿ƒç†æµ‹è¯•',
    'æ˜Ÿç›˜',
    'å¡”ç½—',
    'å æ˜Ÿ',
    'è¿åŠ¿åˆ†æ',
    'æ°´é€†æœŸ',
    'å¸å¼•åŠ›',
    'æ˜¾åŒ–æ³•åˆ™',
    'MBTIæµ‹è¯•',
    'æ€§æ ¼æµ‹è¯•',
    'æƒ…æ„Ÿå’¨è¯¢',
    'å­¦ä¸šå’¨è¯¢',
    'èŒä¸šè§„åˆ’',
    'é¢è¯•æŠ€å·§',
    'è€ƒè¯•ç„¦è™‘',
    'åˆ†æ‰‹å¤åˆ',
    'æ‹çˆ±æŠ€å·§',
    # æ–°å¢å…³é”®è¯ï¼ˆæ‰©å¤§è¦†ç›–èŒƒå›´ï¼‰
    'é™¶ç™½ç™½',
    'æ˜Ÿåº§',
    'æƒ…æ„Ÿåˆ†æ',
    'å¿ƒç†åˆ†æ',
    'æ€§æ ¼åˆ†æ',
    'äººæ ¼æµ‹è¯•',
    'å¿ƒç†æ…°è—‰',
    'æƒ…æ„ŸæŒ‡å¯¼',
    'å­¦ä¸šæŒ‡å¯¼',
    'èŒä¸šå»ºè®®',
    'é¢è¯•æŒ‡å¯¼',
    'è€ƒè¯•å»ºè®®',
    'å¤åˆå»ºè®®',
    'åˆ†æ‰‹å»ºè®®',
    'æ‹çˆ±æŒ‡å¯¼',
    'æƒ…æ„Ÿè§£æƒ‘',
    'å¿ƒç†æ”¯æŒ',
    'æƒ…ç»ªç®¡ç†',
    'ç„¦è™‘ç¼“è§£',
    'å‹åŠ›ç¼“è§£',
    'æƒ…æ„Ÿç­”ç–‘',
    'å¿ƒç†ç­”ç–‘',
    'è¿åŠ¿é¢„æµ‹',
    'æœªæ¥é¢„æµ‹',
    'äººç”Ÿå»ºè®®',
    'ç”Ÿæ´»å»ºè®®',
    'å†³ç­–å»ºè®®',
    'é€‰æ‹©å›°éš¾',
    'è¿·èŒ«',
    'å›°æƒ‘',
    'æ±‚åŠ©',
    'å’¨è¯¢',
    'åˆ†æ',
    'è§£è¯»',
    'æŒ‡å¼•',
    'æŒ‡å¯¼',
    'å»ºè®®',
    'æ–¹æ³•',
    'æŠ€å·§',
    'ç­–ç•¥'
]


MAX_PAGES = 30         # æ¯ä¸ªå…³é”®è¯æœ€å¤šæŠ“å¤šå°‘é¡µï¼ˆå¢åŠ åˆ°30é¡µä»¥è·å¾—æ›´å¤šæ•°æ®ï¼‰
TARGET_TOTAL = 3000    # ç›®æ ‡æ€»æ•°ï¼ˆæé«˜åˆ°3000æ¡ä»¥è·å¾—æ›´å……è¶³çš„æ•°æ®ï¼‰
MIN_TOTAL = 1500       # æœ€å°‘æŠ“å–æ•°é‡ï¼ˆæé«˜åˆ°1500æ¡ï¼‰
EMPTY_LIMIT = 3        # è¿ç»­ç©ºé¡µæ•°é™åˆ¶ï¼ˆå¢åŠ åˆ°3ï¼‰

# Session + Retry
session = requests.Session()
retry_strategy = Retry(
    total=5,
    backoff_factor=2,
    status_forcelist=[429, 500, 502, 503, 504],
    allowed_methods=["GET"],
    raise_on_status=False
)
adapter = HTTPAdapter(max_retries=retry_strategy)
session.mount("https://", adapter)

all_weibos = []

for kw_idx, keyword in enumerate(KEYWORDS, 1):
    print(f'\n===== Keyword ({kw_idx}/{len(KEYWORDS)}): {keyword} =====')
    empty_pages = 0
    page_count = 0
    since_id = None
    search_ssid = None
    search_vsid = None
    containerid_base = None
    last_weibo_id = None  # ä¿å­˜æœ€åä¸€ä¸ªå¾®åšIDï¼Œç”¨äºç¿»é¡µ

    while page_count < MAX_PAGES and len(all_weibos) < TARGET_TOTAL:
        # æ„å»ºè¯·æ±‚å‚æ•°
        if page_count == 0:
            # ç¬¬ä¸€é¡µä½¿ç”¨ containerid
            params = {
                'containerid': f'100103type=1&q={keyword}',
                'page_type': 'searchall'
            }
        else:
            # åç»­é¡µé¢ï¼šä¼˜å…ˆä½¿ç”¨æœ€åä¸€ä¸ªå¾®åšIDä½œä¸ºsince_idï¼ˆæœ€å¯é ï¼‰
            if last_weibo_id:
                params = {
                    'containerid': f'100103type=1&q={keyword}',
                    'page_type': 'searchall',
                    'since_id': last_weibo_id
                }
                if search_ssid:
                    params['search_ssid'] = search_ssid
                if search_vsid:
                    params['search_vsid'] = search_vsid
                print(f'  [è°ƒè¯•] ä½¿ç”¨since_id={last_weibo_id}ç¿»é¡µ')
            elif containerid_base:
                # ä½¿ç”¨å®Œæ•´çš„containerid + page
                params = {
                    'containerid': containerid_base,
                    'page_type': 'searchall',
                    'page': page_count + 1
                }
                if search_ssid:
                    params['search_ssid'] = search_ssid
                if search_vsid:
                    params['search_vsid'] = search_vsid
                print(f'  [è°ƒè¯•] ä½¿ç”¨containerid_base + page={page_count + 1}')
            elif since_id:
                # ä½¿ç”¨APIè¿”å›çš„since_id
                params = {
                    'containerid': f'100103type=1&q={keyword}',
                    'page_type': 'searchall',
                    'since_id': since_id
                }
                if search_ssid:
                    params['search_ssid'] = search_ssid
                if search_vsid:
                    params['search_vsid'] = search_vsid
                print(f'  [è°ƒè¯•] ä½¿ç”¨APIè¿”å›çš„since_id={since_id}')
            else:
                # æœ€åå°è¯•ï¼šä½¿ç”¨pageå‚æ•°
                params = {
                    'containerid': f'100103type=1&q={keyword}',
                    'page_type': 'searchall',
                    'page': page_count + 1
                }
                if search_ssid:
                    params['search_ssid'] = search_ssid
                if search_vsid:
                    params['search_vsid'] = search_vsid
                print(f'  [è°ƒè¯•] ä½¿ç”¨page={page_count + 1}ï¼ˆæœ€åå°è¯•ï¼‰')

        success = False
        for attempt in range(3):
            try:
                resp = session.get(
                    'https://m.weibo.cn/api/container/getIndex',
                    headers=headers,
                    params=params,
                    timeout=20,
                    verify=False
                )
                
                # æ£€æŸ¥å“åº”çŠ¶æ€
                if resp.status_code != 200:
                    print(f'  HTTP {resp.status_code}, retrying...')
                    time.sleep(random.uniform(3, 6))
                    continue
                
                data = resp.json()
                
                # æ£€æŸ¥APIè¿”å›çŠ¶æ€
                if data.get('ok') != 1:
                    print(f'  APIè¿”å›é”™è¯¯: {data.get("msg", "æœªçŸ¥é”™è¯¯")}')
                    if data.get('msg') and 'é¢‘ç¹' in data.get('msg', ''):
                        print('  âš ï¸ å¯èƒ½è§¦å‘é¢‘ç‡é™åˆ¶ï¼Œç­‰å¾…æ›´é•¿æ—¶é—´...')
                        time.sleep(random.uniform(30, 60))
                    break
                
                # ä¿å­˜ä¼šè¯ä¿¡æ¯ï¼ˆç¬¬ä¸€é¡µï¼‰
                if page_count == 0:
                    cardlist_info = data.get('data', {}).get('cardlistInfo', {})
                    # ä¿å­˜æœç´¢ä¼šè¯ID
                    search_ssid = cardlist_info.get('search_ssid')
                    search_vsid = cardlist_info.get('search_vsid')
                    containerid_base = cardlist_info.get('containerid')
                    
                    # è°ƒè¯•ä¿¡æ¯
                    print(f'  [è°ƒè¯•] total: {cardlist_info.get("total", 0)} æ¡ç»“æœ')
                    print(f'  [è°ƒè¯•] page_size: {cardlist_info.get("page_size", 0)}')
                    if search_ssid:
                        print(f'  [è°ƒè¯•] search_ssid: {search_ssid[:20]}...')
                    if search_vsid:
                        print(f'  [è°ƒè¯•] search_vsid: {search_vsid[:20]}...')
                    if containerid_base:
                        print(f'  [è°ƒè¯•] containerid: {containerid_base[:50]}...')
                
                success = True
                break
            except json.JSONDecodeError as e:
                print(f'  JSONè§£æå¤±è´¥: {e}')
                print(f'  å“åº”å†…å®¹å‰200å­—ç¬¦: {resp.text[:200]}')
                time.sleep(random.uniform(5, 10))
            except Exception as e:
                print(f'  Attempt {attempt+1} failed: {e}')
                time.sleep(random.uniform(3, 6))

        if not success:
            print('  Skipped this page due to repeated errors.')
            empty_pages += 1
            if empty_pages >= EMPTY_LIMIT:
                break
            continue

        cards = data.get('data', {}).get('cards', [])
        count = 0
        current_page_last_id = None  # å½“å‰é¡µæœ€åä¸€ä¸ªå¾®åšID
        
        for card in cards:
            if card.get('card_type') == 9:
                mblog = card.get('mblog')
                if not mblog:
                    continue
                
                # å»é‡ï¼šæ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒIDçš„å¾®åš
                weibo_id = mblog.get('id')
                if any(w.get('id') == weibo_id for w in all_weibos):
                    continue
                
                all_weibos.append({
                    'platform': 'weibo',
                    'keyword': keyword,
                    'id': weibo_id,
                    'text': mblog.get('text', ''),
                    'created_at': mblog.get('created_at'),
                    'reposts': mblog.get('reposts_count', 0),
                    'comments': mblog.get('comments_count', 0),
                    'likes': mblog.get('attitudes_count', 0),
                    'user': mblog.get('user', {}).get('screen_name', '')
                })
                count += 1
                current_page_last_id = weibo_id  # æ›´æ–°å½“å‰é¡µæœ€åä¸€ä¸ªå¾®åšID
        
        # æ›´æ–°å…¨å±€last_weibo_idï¼ˆç”¨äºä¸‹æ¬¡ç¿»é¡µï¼‰
        if current_page_last_id:
            last_weibo_id = current_page_last_id

        print(f'  Page {page_count+1}: {count} posts (ç´¯è®¡: {len(all_weibos)}/{TARGET_TOTAL})')

        if count == 0:
            empty_pages += 1
            if empty_pages >= EMPTY_LIMIT:
                print(f'  è¿ç»­{EMPTY_LIMIT}é¡µä¸ºç©ºï¼Œåœæ­¢æŠ“å–è¯¥å…³é”®è¯')
                break
        else:
            empty_pages = 0

        # è·å–ä¸‹ä¸€é¡µä¿¡æ¯
        cardlist_info = data.get('data', {}).get('cardlistInfo', {})
        current_page = cardlist_info.get('page', page_count + 1)
        
        # ç¡®ä¿ç±»å‹è½¬æ¢ï¼ˆAPIå¯èƒ½è¿”å›å­—ç¬¦ä¸²ï¼‰
        try:
            total_results = int(cardlist_info.get('total', 0))
        except (ValueError, TypeError):
            total_results = 0
        
        try:
            page_size = int(cardlist_info.get('page_size', 10))
        except (ValueError, TypeError):
            page_size = 10
        
        try:
            current_page = int(current_page)
        except (ValueError, TypeError):
            current_page = page_count + 1
        
        # è®¡ç®—æ€»é¡µæ•°
        if total_results > 0 and page_size > 0:
            total_pages = (total_results + page_size - 1) // page_size
            print(f'  [ä¿¡æ¯] å½“å‰é¡µ: {current_page}/{total_pages}, æ¯é¡µ: {page_size}æ¡')
        
        # å°è¯•è·å– since_id
        since_id = cardlist_info.get('since_id')
        if not since_id:
            since_id = cardlist_info.get('since_id_str') or cardlist_info.get('next_cursor')
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šé¡µé¢
        if total_results > 0:
            estimated_current = (current_page - 1) * page_size + count
            if estimated_current >= total_results:
                print(f'  å·²æŠ“å– {estimated_current}/{total_results}ï¼Œæ²¡æœ‰æ›´å¤šæ•°æ®äº†')
                break
        elif count == 0 and page_count > 0:
            # å¦‚æœè¿ç»­å¤šé¡µéƒ½æ˜¯0æ¡ï¼Œå¯èƒ½æ²¡æœ‰æ›´å¤šæ•°æ®äº†
            print(f'  è¿ç»­å¤šé¡µæ— æ•°æ®ï¼Œå¯èƒ½å·²æŠ“å–å®Œæ¯•')
            break

        page_count += 1
        
        # åŠ¨æ€è°ƒæ•´ç­‰å¾…æ—¶é—´ï¼šæ¥è¿‘ç›®æ ‡æ—¶åŠ å¿«é€Ÿåº¦
        if len(all_weibos) < TARGET_TOTAL * 0.8:
            time.sleep(random.uniform(5, 10))
        else:
            time.sleep(random.uniform(3, 6))
        
        # å¦‚æœå·²è¾¾åˆ°ç›®æ ‡æ•°é‡ï¼Œæå‰ç»“æŸ
        if len(all_weibos) >= TARGET_TOTAL:
            print(f'  âœ… å·²è¾¾åˆ°ç›®æ ‡æ•°é‡ {TARGET_TOTAL}ï¼Œåœæ­¢æŠ“å–')
            break

    # å…³é”®è¯é—´ç­‰å¾…æ—¶é—´
    if kw_idx < len(KEYWORDS):
        wait_time = random.uniform(15, 25)
        print(f'  ç­‰å¾… {wait_time:.1f} ç§’åç»§ç»­ä¸‹ä¸€ä¸ªå…³é”®è¯...')
        time.sleep(wait_time)
    
    # å¦‚æœå·²è¾¾åˆ°ç›®æ ‡æ•°é‡ï¼Œæå‰ç»“æŸæ‰€æœ‰å…³é”®è¯
    if len(all_weibos) >= TARGET_TOTAL:
        print(f'\nâœ… å·²è¾¾åˆ°ç›®æ ‡æ•°é‡ {TARGET_TOTAL}ï¼Œåœæ­¢æ‰€æœ‰æŠ“å–')
        break

# æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å°‘æ•°é‡
if len(all_weibos) < MIN_TOTAL:
    print(f'\nâš ï¸ è­¦å‘Šï¼šåªæŠ“å–äº† {len(all_weibos)} æ¡æ•°æ®ï¼Œå°‘äºç›®æ ‡æœ€å°‘æ•°é‡ {MIN_TOTAL}')
    print('å»ºè®®ï¼š')
    print('  1. æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒCookieæ˜¯å¦æœ‰æ•ˆ')
    print('  2. å¢åŠ  MAX_PAGESï¼ˆå½“å‰30é¡µï¼‰æˆ–æ·»åŠ æ›´å¤šå…³é”®è¯ï¼ˆå½“å‰å·²æ‰©å±•è‡³80+ä¸ªå…³é”®è¯ï¼‰')
    print('  3. æ£€æŸ¥æ˜¯å¦è§¦å‘åçˆ¬è™«é™åˆ¶')
    print(f'  4. å¦‚éœ€æ›´å¤šæ•°æ®ï¼Œå¯å°† MAX_PAGES è°ƒæ•´è‡³50-100ï¼ŒTARGET_TOTAL è°ƒæ•´è‡³5000+')
else:
    print(f'\nâœ… æˆåŠŸæŠ“å– {len(all_weibos)} æ¡æ•°æ®ï¼ˆç›®æ ‡: {MIN_TOTAL}-{TARGET_TOTAL}ï¼‰')
    if len(all_weibos) >= TARGET_TOTAL:
        print(f'  å·²è¾¾åˆ°ç›®æ ‡æ•°é‡ï¼Œæ•°æ®å……è¶³ï¼')
    elif len(all_weibos) >= MIN_TOTAL:
        print(f'  æ•°æ®é‡å……è¶³ï¼Œå¯è¿›è¡Œåˆ†æ')

# ç»Ÿè®¡æ¯ä¸ªå…³é”®è¯çš„æ•°æ®é‡
print('\nğŸ“Š å„å…³é”®è¯æ•°æ®ç»Ÿè®¡:')
keyword_stats = {}
for weibo in all_weibos:
    kw = weibo.get('keyword', 'unknown')
    keyword_stats[kw] = keyword_stats.get(kw, 0) + 1

for kw, count in sorted(keyword_stats.items(), key=lambda x: x[1], reverse=True):
    print(f'  {kw}: {count} æ¡')

output = f'weibo_data_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
with open(output, 'w', encoding='utf-8') as f:
    json.dump(all_weibos, f, ensure_ascii=False, indent=2)

print(f'\nâœ” å·²ä¿å­˜ {len(all_weibos)} æ¡å¾®åšæ•°æ®åˆ° {output}')
print(f'   æ–‡ä»¶å¤§å°: {len(json.dumps(all_weibos, ensure_ascii=False).encode("utf-8")) / 1024 / 1024:.2f} MB')
